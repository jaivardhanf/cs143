from pyspark import SparkContext
sc = SparkContext("local", "BookPairs")

data = sc.textFile("goodreads.user.books1000")
pairs = data.flatmap(lambda line: [(m,s) for m in line.split(":")[1].split(",") for s in line.split(":")[1].split(",") if s<m])
pairs1 = pairs.map(lambda p:(p,1))
BookPairs = pairs1.reduceByKey(lambda a,b:a+b)

HighfreqPairs = BookPairs.filter(lambda (((bookid1, bookid2), count): count > 20).collect()

HighfreqPairs.saveAsTextFile("output")
